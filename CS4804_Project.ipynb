{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BbghijqxOSP"
      },
      "source": [
        "# **INTRO TO AI PROJECT**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIe3Sr_XxDaM"
      },
      "source": [
        "# **Package installs, import statements, and misc**\n",
        "\n",
        "You will also have to add the HuggingFace API Key in the Secrets section of this colab. It is the key icon to the left. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SGaB0n-l0lEJ"
      },
      "outputs": [],
      "source": [
        "# !pip install -q kaggle\n",
        "# !pip install -q huggingface_hub\n",
        "# !pip install googletrans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"PyTorch built with CUDA version:\", torch.version.cuda)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an2PmoHLRdwm"
      },
      "outputs": [],
      "source": [
        "import unsloth\n",
        "from datasets import load_dataset\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8nC6jM9wWpB"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets list "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vBInt1xZnH"
      },
      "source": [
        "## **Dataset Downloads and Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50161676"
      },
      "source": [
        "### **Downloading from Kaggle**\n",
        "\n",
        "To download a dataset from Kaggle, you first need to find the dataset's identifier. This usually looks like `username/dataset-name`. You can find this on the dataset's page on Kaggle. Once you have it, you use the `!kaggle datasets download` command, and then `unzip` the downloaded file if it's a zip archive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ba706b2a"
      },
      "outputs": [],
      "source": [
        "# Load Twitter Data\n",
        "# !kaggle datasets download mrmorj/hate-speech-and-offensive-language-dataset\n",
        "# !unzip hate-speech-and-offensive-language-dataset.zip\n",
        "# !mv labeled_data.csv twitter_hate_speech_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uwllAu52LghZ"
      },
      "outputs": [],
      "source": [
        "# # Load Twitter Data\n",
        "# !kaggle datasets download mrmorj/hate-speech-and-offensive-language-dataset\n",
        "# !unzip hate-speech-and-offensive-language-dataset.zip\n",
        "# !mv labeled_data.csv twitter_hate_speech_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LwPYR7eFLrvX"
      },
      "outputs": [],
      "source": [
        "# # Load Wikipedia Data\n",
        "# # TO-DO: This data is copied from the competition, we need to check that its actually the same as the competition\n",
        "# !kaggle datasets download julian3833/jigsaw-toxic-comment-classification-challenge\n",
        "# !unzip jigsaw-toxic-comment-classification-challenge.zip\n",
        "\n",
        "# target_path = os.path.expanduser('~/wikipedia')\n",
        "\n",
        "# if not os.path.exists(target_path):\n",
        "#   !mkdir wikipedia_data\n",
        "# else:\n",
        "#   print(f\"Directory already found at {target_path}. Replacing files\")\n",
        "\n",
        "# !mv sample_submission.csv wikipedia_data\n",
        "# !mv test.csv wikipedia_data\n",
        "# !mv test_labels.csv wikipedia_data\n",
        "# !mv train.csv wikipedia_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6971ed9b"
      },
      "source": [
        "### **Downloading from Hugging Face**\n",
        "\n",
        "For Hugging Face, you can use the `huggingface_hub` library. The primary function for downloading files is `hf_hub_download`. You'll need the `repo_id` (e.g., 'HuggingFaceH4/ultrachat_200k') and the `filename` you want to download from that repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "arlZof7bQ093"
      },
      "outputs": [],
      "source": [
        "anthropic_data = load_dataset(\"Anthropic/hh-rlhf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lzaJbd_kwn6J"
      },
      "outputs": [],
      "source": [
        "# prosocial_dataset = load_dataset(\"allenai/prosocial-dialog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e8B82RxIRBge"
      },
      "outputs": [],
      "source": [
        "toxigen_dataset = load_dataset(\"toxigen/toxigen-data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p95QW2JeRPJu"
      },
      "outputs": [],
      "source": [
        "real_toxicity_dataset = load_dataset(\"allenai/real-toxicity-prompts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1roWeiZRS0G"
      },
      "outputs": [],
      "source": [
        "# print(anthropic_data)\n",
        "# print(prosocial_dataset)\n",
        "print(toxigen_dataset)\n",
        "print(real_toxicity_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NegKLeGghJxj"
      },
      "source": [
        "## **Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag4YlyVbhJxk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "print(\" Processing libraries imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZCcQd_Ql3ET"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if pd.isna(text) or text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = ' '.join(text.split())\n",
        "    return text.strip()\n",
        "\n",
        "def extract_metadata(text):\n",
        "    return {\n",
        "        'length': len(text),\n",
        "        'word_count': len(text.split()),\n",
        "        'has_mentions': '@' in text,\n",
        "        'has_hashtags': '#' in text,\n",
        "        'has_caps': any(c.isupper() for c in text),\n",
        "        'exclamation_count': text.count('!'),\n",
        "        'question_count': text.count('?')\n",
        "    }\n",
        "\n",
        "print(\"Help functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhE8gq_Dl7OD"
      },
      "outputs": [],
      "source": [
        "def process_twitter_data():\n",
        "    print(\"Processing Twitter dataset (Human-Generated, Social Media)...\")\n",
        "    twitter_df = pd.read_csv('twitter_hate_speech_data.csv')\n",
        "    twitter_df['text'] = twitter_df['tweet'].apply(clean_text)\n",
        "    twitter_df['binary_label'] = twitter_df['class'].apply(lambda x: 1 if x in [0, 1] else 0)\n",
        "    twitter_df['three_class_label'] = twitter_df['class']\n",
        "    twitter_df['source'] = 'twitter'\n",
        "    twitter_df['origin'] = 'human'\n",
        "    twitter_df['domain'] = 'social_media'\n",
        "    metadata = twitter_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        twitter_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    twitter_df = twitter_df[twitter_df['text'].str.len() > 0].reset_index(drop=True)\n",
        "    print(f\"  Twitter: {len(twitter_df)} examples\")\n",
        "    print(f\"  Hate speech: {(twitter_df['three_class_label'] == 0).sum()}\")\n",
        "    print(f\"  Offensive: {(twitter_df['three_class_label'] == 1).sum()}\")\n",
        "    print(f\"  None: {(twitter_df['three_class_label'] == 2).sum()}\")\n",
        "    return twitter_df\n",
        "\n",
        "print(\" Twitter processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkDhwZ8smBFZ"
      },
      "outputs": [],
      "source": [
        "def process_wikipedia_data():\n",
        "    print(\"\\nProcessing Wikipedia dataset (Human-Generated, Non-Social Media)...\")\n",
        "    wiki_df = pd.read_csv('wikipedia_data/train.csv')\n",
        "    wiki_df['text'] = wiki_df['comment_text'].apply(clean_text)\n",
        "    toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "    wiki_df['binary_label'] = wiki_df[toxic_cols].max(axis=1)\n",
        "    for col in toxic_cols:\n",
        "        wiki_df[f'label_{col}'] = wiki_df[col]\n",
        "    wiki_df['toxicity_severity'] = wiki_df[toxic_cols].sum(axis=1)\n",
        "    wiki_df['source'] = 'wikipedia'\n",
        "    wiki_df['origin'] = 'human'\n",
        "    wiki_df['domain'] = 'non_social_media'\n",
        "    metadata = wiki_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        wiki_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    wiki_df = wiki_df[wiki_df['text'].str.len() > 0].reset_index(drop=True)\n",
        "    print(f\" Wikipedia: {len(wiki_df)} examples\")\n",
        "    print(f\"   Toxic: {wiki_df['binary_label'].sum()}\")\n",
        "    print(f\"   Non-Toxic: {len(wiki_df) - wiki_df['binary_label'].sum()}\")\n",
        "    return wiki_df\n",
        "\n",
        "print(\" Wikipedia processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn77pMxTmGN4"
      },
      "outputs": [],
      "source": [
        "def process_anthropic_data(anthropic_data):\n",
        "    print(\"\\nProcessing Anthropic HH-RLHF (Human Feedback on AI)...\")\n",
        "    texts = []\n",
        "    labels = []\n",
        "    response_types = []\n",
        "    for split_name in ['train', 'test']:\n",
        "        for example in anthropic_data[split_name]:\n",
        "            chosen = clean_text(example['chosen'])\n",
        "            rejected = clean_text(example['rejected'])\n",
        "            if len(chosen) > 0:\n",
        "                texts.append(chosen)\n",
        "                labels.append(0)\n",
        "                response_types.append('chosen')\n",
        "            if len(rejected) > 0:\n",
        "                texts.append(rejected)\n",
        "                labels.append(1)\n",
        "                response_types.append('rejected')\n",
        "    anthropic_df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'binary_label': labels,\n",
        "        'response_type': response_types,\n",
        "        'source': 'anthropic',\n",
        "        'origin': 'machine_generated',\n",
        "        'domain': 'mixed'\n",
        "    })\n",
        "    metadata = anthropic_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        anthropic_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    print(f\"  Anthropic: {len(anthropic_df)} examples\")\n",
        "    print(f\"    Rejected (harmful): {anthropic_df['binary_label'].sum()}\")\n",
        "    print(f\"    Chosen (liked): {len(anthropic_df) - anthropic_df['binary_label'].sum()}\")\n",
        "    return anthropic_df\n",
        "\n",
        "print(\"Anthropic processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_anthropic_data_modified(anthropic_data):\n",
        "    print(\"\\nProcessing Anthropic HH-RLHF (Human Feedback on AI)...\")\n",
        "    texts = []\n",
        "    labels = []\n",
        "    response_types = []\n",
        "    for split_name in ['train', 'test']:\n",
        "        for example in anthropic_data[split_name]:\n",
        "            chosen_list = example['chosen'].split(\"\\n\\n\")[1:]\n",
        "            real_chosen_list = list()\n",
        "            for segment in chosen_list:\n",
        "                if segment.startswith(\"Human:\") or segment.startswith(\"Assistant:\"):\n",
        "                    real_chosen_list.append(segment)\n",
        "                else:\n",
        "                    real_chosen_list[-1] = real_chosen_list[-1] + '\\n\\n' + segment\n",
        "                \n",
        "            chosen = clean_text(real_chosen_list[-1])\n",
        "\n",
        "            if chosen.startswith(\"Assistant:\") and len(chosen) > 150:\n",
        "               chosen = chosen[len(\"Assistant:\"):]\n",
        "               texts.append(chosen)\n",
        "               labels.append(0)\n",
        "               response_types.append('chosen')\n",
        "\n",
        "    anthropic_df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'binary_label': labels,\n",
        "        'response_type': response_types,\n",
        "        'source': 'anthropic',\n",
        "        'origin': 'machine_generated',\n",
        "        'domain': 'mixed'\n",
        "    })\n",
        "    metadata = anthropic_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        anthropic_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    print(f\"  Anthropic: {len(anthropic_df)} examples\")\n",
        "    print(f\"    Rejected (harmful): {anthropic_df['binary_label'].sum()}\")\n",
        "    print(f\"    Chosen (liked): {len(anthropic_df) - anthropic_df['binary_label'].sum()}\")\n",
        "    return anthropic_df\n",
        "\n",
        "print(\"Anthropic processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOi4gREYmMF3"
      },
      "outputs": [],
      "source": [
        "def process_prosocial_data(prosocial_dataset):\n",
        "    print(\"\\nProcessing ProsocialDialog (Conversational Safety)...\")\n",
        "    texts = []\n",
        "    labels = []\n",
        "    safety_labels = []\n",
        "    for split_name in ['train', 'validation']:\n",
        "        for example in prosocial_dataset[split_name]:\n",
        "            context = example['context']\n",
        "            response = example['response']\n",
        "            full_text = f\"{context} {response}\".strip()\n",
        "            clean = clean_text(full_text)\n",
        "            safety = example['safety_label']\n",
        "            is_unsafe = 0 if safety == '__casual__' else 1\n",
        "            if len(clean) > 0:\n",
        "                texts.append(clean)\n",
        "                labels.append(is_unsafe)\n",
        "                safety_labels.append(safety)\n",
        "    prosocial_df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'binary_label': labels,\n",
        "        'safety_annotation': safety_labels,\n",
        "        'source': 'prosocial',\n",
        "        'origin': 'mixed',\n",
        "        'domain': 'conversational'\n",
        "    })\n",
        "    metadata = prosocial_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        prosocial_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    print(f\"  ProsocialDialog: {len(prosocial_df)} examples\")\n",
        "    print(f\"    Unsafe: {prosocial_df['binary_label'].sum()}\")\n",
        "    print(f\"    Safe: {len(prosocial_df) - prosocial_df['binary_label'].sum()}\")\n",
        "    return prosocial_df\n",
        "\n",
        "print(\" Prosocial processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2usmqS_KmQRB"
      },
      "outputs": [],
      "source": [
        "def process_toxigen_data(toxigen_dataset):\n",
        "    print(\"\\nProcessing ToxiGen ...\")\n",
        "\n",
        "    texts = []\n",
        "    labels = []\n",
        "    target_groups = []\n",
        "    human_scores = []\n",
        "    ai_scores = []\n",
        "    final_scores = []\n",
        "    source_used = []\n",
        "\n",
        "    for example in toxigen_dataset['train']:\n",
        "        text = clean_text(example['text'])\n",
        "\n",
        "        human_tox = example.get('toxicity_human')\n",
        "        ai_tox = example.get('toxicity_ai')\n",
        "\n",
        "        if human_tox and ai_tox:\n",
        "          final_tox = (human_tox + ai_tox) / 2.0\n",
        "        elif human_tox:\n",
        "          final_tox = human_tox\n",
        "        elif ai_tox:\n",
        "          final_tox = ai_tox\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "        if example.get(\"actual_method\") == 'topk':\n",
        "          source = 'machine_generated'\n",
        "        elif example.get(\"actual_method\") == 'cbs':\n",
        "          source = 'human'\n",
        "        if len(text) > 0:\n",
        "            label = 1 if final_tox > 3.0 else 0\n",
        "\n",
        "            texts.append(text)\n",
        "            labels.append(label)\n",
        "            target_groups.append(example.get('target_group', 'unknown'))\n",
        "\n",
        "            human_scores.append(human_tox if human_tox is not None else -1)\n",
        "            ai_scores.append(ai_tox if ai_tox is not None else -1)\n",
        "            final_scores.append(final_tox)\n",
        "            source_used.append(source)\n",
        "\n",
        "    toxigen_df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'binary_label': labels,\n",
        "        'toxicity_final': final_scores,\n",
        "        'toxicity_human': human_scores,\n",
        "        'toxicity_ai': ai_scores,\n",
        "        'origin': source_used,\n",
        "        'target_group': target_groups,\n",
        "        'source': 'toxigen',\n",
        "        'domain': 'synthetic'\n",
        "    })\n",
        "    metadata = toxigen_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        toxigen_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "\n",
        "    print(f\"  ToxiGen processed: {len(toxigen_df)} examples\")\n",
        "    print(f\"    Toxic: {toxigen_df['binary_label'].sum()}\")\n",
        "    print(f\"    Safe: {len(toxigen_df) - toxigen_df['binary_label'].sum()}\")\n",
        "    print(f\"    Human-labeled: {sum(toxigen_df['origin']=='human')}\")\n",
        "    print(f\"    AI-labeled: {sum(toxigen_df['origin']=='machine_generated')}\")\n",
        "\n",
        "    return toxigen_df\n",
        "\n",
        "print(\"  Updated ToxiGen processing function defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8QisubmUj-"
      },
      "outputs": [],
      "source": [
        "def process_real_toxicity_data(real_toxicity_dataset):\n",
        "    print(\"\\nProcessing RealToxicityPrompts (API-Scored Prompts)...\")\n",
        "    texts = []\n",
        "    labels = []\n",
        "    toxicity_scores = []\n",
        "    for example in real_toxicity_dataset['train']:\n",
        "        prompt_dict = example['prompt']\n",
        "        if isinstance(prompt_dict, dict):\n",
        "            text = prompt_dict.get('text', '')\n",
        "            toxicity = prompt_dict.get('toxicity')\n",
        "        else:\n",
        "            text = str(prompt_dict)\n",
        "            toxicity = None\n",
        "        clean = clean_text(text)\n",
        "        if len(clean) > 0:\n",
        "            texts.append(clean)\n",
        "            if toxicity is not None and not pd.isna(toxicity):\n",
        "                tox_score = float(toxicity)\n",
        "                toxicity_scores.append(tox_score)\n",
        "                labels.append(1 if tox_score > 0.5 else 0)\n",
        "            else:\n",
        "                toxicity_scores.append(0.0)\n",
        "                labels.append(0)\n",
        "    real_tox_df = pd.DataFrame({\n",
        "        'text': texts,\n",
        "        'binary_label': labels,\n",
        "        'toxicity_score': toxicity_scores,\n",
        "        'source': 'real_toxicity_prompts',\n",
        "        'origin': 'human',\n",
        "        'domain': 'web_text'\n",
        "    })\n",
        "    metadata = real_tox_df['text'].apply(extract_metadata)\n",
        "    for key in metadata.iloc[0].keys():\n",
        "        real_tox_df[f'meta_{key}'] = metadata.apply(lambda x: x[key])\n",
        "    print(f\"  RealToxicityPrompts: {len(real_tox_df)} examples\")\n",
        "    print(f\"    Toxic (>0.5): {real_tox_df['binary_label'].sum()}\")\n",
        "    print(f\"    Non-toxic: {len(real_tox_df) - real_tox_df['binary_label'].sum()}\")\n",
        "    return real_tox_df\n",
        "\n",
        "print(\"  RealToxicity processing function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgePBroyma8A"
      },
      "outputs": [],
      "source": [
        "def create_simple_splits(twitter_df, wiki_df, anthropic_df, prosocial_df, toxigen_df, real_tox_df):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING TRAIN/VAL/TEST SPLITS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Combines all data\n",
        "    all_data = pd.concat([twitter_df, wiki_df], ignore_index=True, join='inner')\n",
        "    all_data = pd.concat([all_data, anthropic_df], ignore_index=True) # This dataset is not as clear-cut in toxicity vs non-toxicity\n",
        "    # all_data = pd.concat([all_data, prosocial_df], ignore_index=True) # This dataset is better, but still has some odd spots\n",
        "    all_data = pd.concat([all_data, toxigen_df], ignore_index=True, join='inner')\n",
        "    all_data = pd.concat([all_data, real_tox_df], ignore_index=True, join='inner')\n",
        "\n",
        "    # Shuffles it\n",
        "    all_data = all_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Creates 70/15/15 split\n",
        "    n = len(all_data)\n",
        "    train_end = int(0.7 * n)\n",
        "    val_end = int(0.85 * n)\n",
        "\n",
        "    train_df = all_data[:train_end]\n",
        "    val_df = all_data[train_end:val_end]\n",
        "    test_df = all_data[val_end:]\n",
        "\n",
        "    print(f\"\\nTrain: {len(train_df):,} examples\")\n",
        "    print(f\"Val: {len(val_df):,} examples\")\n",
        "    print(f\"Test: {len(test_df):,} examples\")\n",
        "\n",
        "    # Save the splits\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SAVING FILES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    train_df.to_csv('train.csv', index=False)\n",
        "    val_df.to_csv('val.csv', index=False)\n",
        "    test_df.to_csv('test.csv', index=False)\n",
        "    all_data.to_csv('all_data.csv', index=False)\n",
        "\n",
        "    print(\"  Files saved:\")\n",
        "    print(\"  - train.csv\")\n",
        "    print(\"  - val.csv\")\n",
        "    print(\"  - test.csv\")\n",
        "    print(\"  - all_data.csv\")\n",
        "\n",
        "    return train_df, val_df, test_df, all_data\n",
        "\n",
        "print(\"Split function made\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYionMU7nVXn"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STARTING DATA PROCESSING PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "# prosocial_df = process_prosocial_data(prosocial_dataset)\n",
        "prosocial_df = pd.DataFrame() # Not clear cut\n",
        "\n",
        "# Additional Processing\n",
        "anthropic_df = process_anthropic_data_modified(anthropic_data) # Only taking chosen responses\n",
        "if len(anthropic_df) > 36000:\n",
        "    anthropic_df = anthropic_df.sample(n=36000, random_state=42)\n",
        "    \n",
        "twitter_df = process_twitter_data()\n",
        "\n",
        "# Extended processing to remove \n",
        "wiki_df = process_wikipedia_data()\n",
        "wiki_label_0 = wiki_df[wiki_df['binary_label'] == 0]\n",
        "wiki_label_1 = wiki_df[wiki_df['binary_label'] == 1]\n",
        "\n",
        "# Take max 48k from the safe (label 0) portion\n",
        "if len(wiki_label_0) > 48000:\n",
        "    # random_state ensures you get the same 48k every time you run it\n",
        "    wiki_label_0 = wiki_label_0.sample(n=48000, random_state=42) \n",
        "\n",
        "# Combine: 48k Safe + ALL Toxic\n",
        "wiki_df = pd.concat([wiki_label_0, wiki_label_1])\n",
        "\n",
        "toxigen_df = process_toxigen_data(toxigen_dataset)\n",
        "real_tox_df = process_real_toxicity_data(real_toxicity_dataset)\n",
        "\n",
        "# Call the function to create splits and assign to global dataframes\n",
        "train_df, val_df, test_df, all_data = create_simple_splits(twitter_df, wiki_df, anthropic_df, prosocial_df, toxigen_df, real_tox_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "toxigen_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0vy0Sh0nazG"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Final dataset summary\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTotal examples: {len(all_data):,}\")\n",
        "print(f\"\\nBy Origin:\")\n",
        "print(all_data['origin'].value_counts())\n",
        "print(f\"\\nBy Domain:\")\n",
        "print(all_data['domain'].value_counts())\n",
        "print(f\"\\nBy Source:\")\n",
        "print(all_data['source'].value_counts())\n",
        "print(f\"\\nLabel Distribution:\")\n",
        "toxic_count = all_data['binary_label'].sum()\n",
        "print(f\"  Toxic: {toxic_count:,} ({all_data['binary_label'].mean()*100:.1f}%)\")\n",
        "print(f\"  Safe: {(len(all_data)-toxic_count):,} ({(1-all_data['binary_label'].mean())*100:.1f}%)\")\n",
        "print(\"\\n  data processing done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSxjGYhAJXla"
      },
      "source": [
        "## **Machine Learning Attempts**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvjlQ4AXJ952"
      },
      "source": [
        "### Other Model Approaches\n",
        "\n",
        "Since our main focus is on LLMs and toxicity, we will put most of our effort towards that. However, for some comparisons, we will provide some other models and how they perform.\n",
        "\n",
        "We will be providing Naive Bayes, Logistic Regression, and SVM approaches. For this portion, we will use SciKit-Learn.\n",
        "\n",
        "SVM (Support Vector Machines) & Logistic Regression typically use TF-IDF (Term Frequency-Inverse Document Frequency) or N-grams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIzcFwbZKPVJ"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes Classifier Implementation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NAIVE BAYES CLASSIFIER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prepare the data\n",
        "X_train = train_df['text'].values\n",
        "y_train = train_df['binary_label'].values\n",
        "\n",
        "X_val = val_df['text'].values\n",
        "y_val = val_df['binary_label'].values\n",
        "\n",
        "X_test = test_df['text'].values\n",
        "y_test = test_df['binary_label'].values\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "print(\"\\nVectorizing text data...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,  # Limit to top 10k features\n",
        "    ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "    min_df=2,            # Ignore terms that appear in fewer than 2 documents\n",
        "    max_df=0.95,         # Ignore terms that appear in more than 95% of documents\n",
        "    strip_accents='unicode',\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "# Fit on training data and transform\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"  Training set shape: {X_train_tfidf.shape}\")\n",
        "print(f\"  Validation set shape: {X_val_tfidf.shape}\")\n",
        "print(f\"  Test set shape: {X_test_tfidf.shape}\")\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "print(\"\\nTraining Naive Bayes classifier...\")\n",
        "nb_classifier = MultinomialNB(alpha=1.0)  # alpha is the smoothing parameter\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "print(\"  Training complete!\")\n",
        "\n",
        "# Make predictions\n",
        "print(\"\\nMaking predictions...\")\n",
        "y_train_pred = nb_classifier.predict(X_train_tfidf)\n",
        "y_val_pred = nb_classifier.predict(X_val_tfidf)\n",
        "y_test_pred = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate on all splits\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERFORMANCE METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for split_name, y_true, y_pred in [\n",
        "    (\"TRAIN\", y_train, y_train_pred),\n",
        "    (\"VALIDATION\", y_val, y_val_pred),\n",
        "    (\"TEST\", y_test, y_test_pred)\n",
        "]:\n",
        "    print(f\"\\n{split_name} SET:\")\n",
        "    print(f\"  Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"  Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"  Recall:    {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"  F1 Score:  {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"\\n  Confusion Matrix:\")\n",
        "    print(f\"    TN: {cm[0,0]:,}  FP: {cm[0,1]:,}\")\n",
        "    print(f\"    FN: {cm[1,0]:,}  TP: {cm[1,1]:,}\")\n",
        "\n",
        "# Detailed classification report for test set\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DETAILED TEST SET CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Safe', 'Toxic']))\n",
        "\n",
        "# Get prediction probabilities\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREDICTION PROBABILITIES\")\n",
        "print(\"=\"*70)\n",
        "train_probs = nb_classifier.predict_proba(X_train_tfidf)[:, 1]\n",
        "val_probs = nb_classifier.predict_proba(X_val_tfidf)[:, 1]\n",
        "test_probs = nb_classifier.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# Add predictions to dataframes\n",
        "train_df_filtered = train_df.copy()\n",
        "train_df_filtered['nb_prediction'] = y_train_pred\n",
        "train_df_filtered['nb_prob_toxic'] = train_probs\n",
        "\n",
        "val_df_filtered = val_df.copy()\n",
        "val_df_filtered['nb_prediction'] = y_val_pred\n",
        "val_df_filtered['nb_prob_toxic'] = val_probs\n",
        "\n",
        "test_df_filtered = test_df.copy()\n",
        "test_df_filtered['nb_prediction'] = y_test_pred\n",
        "test_df_filtered['nb_prob_toxic'] = test_probs\n",
        "\n",
        "print(\"Prediction probabilities added to dataframes\")\n",
        "\n",
        "# Show some example predictions\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE PREDICTIONS (Test Set)\")\n",
        "print(\"=\"*70)\n",
        "sample_indices = np.random.choice(len(test_df_filtered), size=5, replace=False)\n",
        "for idx in sample_indices:\n",
        "    row = test_df_filtered.iloc[idx]\n",
        "    print(f\"\\nText: {row['text'][:100]}...\")\n",
        "    print(f\"  True Label: {'Toxic' if row['binary_label'] == 1 else 'Safe'}\")\n",
        "    print(f\"  Predicted: {'Toxic' if row['nb_prediction'] == 1 else 'Safe'}\")\n",
        "    print(f\"  Probability (Toxic): {row['nb_prob_toxic']:.4f}\")\n",
        "\n",
        "# Save filtered datasets with predictions\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING FILTERED DATASETS\")\n",
        "print(\"=\"*70)\n",
        "train_df_filtered.to_csv('train_nb_filtered.csv', index=False)\n",
        "val_df_filtered.to_csv('val_nb_filtered.csv', index=False)\n",
        "test_df_filtered.to_csv('test_nb_filtered.csv', index=False)\n",
        "\n",
        "print(\"  Files saved:\")\n",
        "print(\"  - train_nb_filtered.csv\")\n",
        "print(\"  - val_nb_filtered.csv\")\n",
        "print(\"  - test_nb_filtered.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NAIVE BAYES PIPELINE COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8mlybjiLh02"
      },
      "source": [
        "### Finetuning Approaches for toxicity identification\n",
        "\n",
        "We will finetune a small transformer for toxicity identification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "spt2fILlLsZq"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/docs/transformers/en/training#fine-tune-a-pretrained-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiTc9p8NjZB2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g5z6N73joEB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install datasets\n",
        "\n",
        "\n",
        "\n",
        "print('Success!')\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# Create a directory to save pretrained models\n",
        "pretrained_models_dir = './pretrained_models_dir'\n",
        "if not os.path.isdir(pretrained_models_dir):\n",
        "  os.mkdir(pretrained_models_dir)\n",
        "print('Model directory created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification, # Switched to SequenceClassification\n",
        "    TrainingArguments, \n",
        "    Trainer\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "if 'pretrained_models_dir' not in locals():\n",
        "    pretrained_models_dir = \"./models\" \n",
        "\n",
        "model_name_or_path = \"answerdotai/ModernBERT-base\"\n",
        "cache_dir = os.path.join(pretrained_models_dir, \"ModernBERT-base\")\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qv455EGlqGc9"
      },
      "outputs": [],
      "source": [
        "def create_new_model():\n",
        "    # Load Model for Sequence Classification (Binary)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name_or_path, \n",
        "        cache_dir=cache_dir,\n",
        "        num_labels=2,\n",
        "        torch_dtype=\"auto\"\n",
        "    )\n",
        "\n",
        "    # Move to Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Our text column is named 'text', not 'sentence'\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=512, truncation=True)\n",
        "\n",
        "def prepare_datasets(df):\n",
        "    dataset_raw = Dataset.from_pandas(df)\n",
        "\n",
        "    tokenized_dataset = dataset_raw.shuffle(seed=97520349).select(\n",
        "        range(min(20000, len(dataset_raw)))\n",
        "    ).map(tokenize_function, batched=True)\n",
        "\n",
        "    keep_columns = ['text', 'input_ids', 'token_type_ids', 'attention_mask', 'binary_label']\n",
        "\n",
        "    columns_to_remove = [\n",
        "        col for col in tokenized_dataset.column_names \n",
        "        if col not in keep_columns and not col.startswith('__')\n",
        "    ]\n",
        "\n",
        "    tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n",
        "    \n",
        "    if \"binary_label\" in tokenized_dataset.column_names:\n",
        "        tokenized_dataset = tokenized_dataset.rename_column(\"binary_label\", \"label\")\n",
        "\n",
        "    tokenized_dataset.set_format(\"torch\")\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JXrqb_q_jZSZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eW140B5fjZf1"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import gc\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "def train_model(model, train_dataset, val_dataset):\n",
        "  peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS, \n",
        "    r=32, \n",
        "    lora_alpha=32, \n",
        "    lora_dropout=0.2,\n",
        "    target_modules=\"all-linear\" \n",
        ")\n",
        "  peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,      # Crucial for 8GB VRAM\n",
        "    gradient_accumulation_steps=1,     # Maintains effective batch size\n",
        "    bf16=True,                          # Saves ~40% memory\n",
        "    dataloader_num_workers=4,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps=625,\n",
        "    save_steps=625,\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=4,\n",
        "    load_best_model_at_end=True,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "  results = []\n",
        "  output_dir = f\"test_trainer_{123456}\"\n",
        "  training_args.output_dir = output_dir\n",
        "  training_args.seed = 123456\n",
        "  trainer = Trainer(\n",
        "        model=peft_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset, # Use our tokenized training data\n",
        "        eval_dataset=val_dataset,   # Use our tokenized validation data\n",
        "        compute_metrics=compute_metrics,\n",
        "  )\n",
        "  trainer.train()\n",
        "  print(trainer.evaluate())\n",
        "  # The 'accuracy' metric returns a dictionary, so access the 'accuracy' key\n",
        "  results.append(trainer.evaluate()['eval_accuracy'])\n",
        "\n",
        "\n",
        "  results = np.array(results)\n",
        "  mean = np.mean(results)\n",
        "  std = np.std(results)\n",
        "  return peft_model, trainer, results, mean, std\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(train_df['origin'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_train_df = train_df[train_df['origin'] == 'human']\n",
        "print(train_df['binary_label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = create_new_model()\n",
        "base_train_dataset = prepare_datasets(train_df)\n",
        "base_val_dataset = prepare_datasets(val_df)\n",
        "print(\"Tokenized datasets prepared.\")\n",
        "peft_model, base_trainer, results, mean, std = train_model(base_model, base_train_dataset, base_val_dataset)\n",
        "print(f\"Accuracy on toxicity dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")\n",
        "\n",
        "merged_model = peft_model.merge_and_unload()\n",
        "\n",
        "# 2. Define a clearer path (don't overwrite the original 'base_model' name!)\n",
        "# Suggested: \"modernbert_finetuned\" or similar\n",
        "save_path = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\base_model\"\n",
        "\n",
        "# 3. Save the FULL model and tokenizer\n",
        "merged_model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Full merged model saved to: {save_path}\")\n",
        "\n",
        "del base_model\n",
        "del peft_model\n",
        "del base_trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "human_toxicity_model = create_new_model()\n",
        "# Intermediate step\n",
        "human_train_df = train_df[train_df['origin'] == 'human']\n",
        "human_val_df = val_df[val_df['origin'] == 'human']\n",
        "\n",
        "human_train_dataset = prepare_datasets(human_train_df)\n",
        "human_val_dataset = prepare_datasets(human_val_df)\n",
        "print(\"Tokenized datasets prepared.\")\n",
        "human_peft_model, base_trainer, results, mean, std = train_model(human_toxicity_model, human_train_dataset, human_val_dataset)\n",
        "print(f\"Accuracy on toxicity dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")\n",
        "\n",
        "merged_model = human_peft_model.merge_and_unload()\n",
        "\n",
        "# 2. Define a clearer path (don't overwrite the original 'base_model' name!)\n",
        "# Suggested: \"modernbert_finetuned\" or similar\n",
        "save_path = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\human_model\"\n",
        "\n",
        "# 3. Save the FULL model and tokenizer\n",
        "merged_model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Full merged model saved to: {save_path}\")\n",
        "\n",
        "del human_toxicity_model\n",
        "del human_peft_model\n",
        "del base_trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "machine_toxicity_model = create_new_model()\n",
        "# Intermediate step\n",
        "machine_train_df = train_df[train_df['origin'] == 'machine_generated']\n",
        "machine_val_df = val_df[val_df['origin'] == 'machine_generated']\n",
        "\n",
        "machine_train_dataset = prepare_datasets(machine_train_df)\n",
        "machine_val_dataset = prepare_datasets(machine_val_df)\n",
        "print(\"Tokenized datasets prepared.\")\n",
        "machine_peft_model, base_trainer, results, mean, std = train_model(machine_toxicity_model, machine_train_dataset, machine_val_dataset)\n",
        "print(f\"Accuracy on toxicity dev set: {mean} +/- {std}\")\n",
        "elapsed_time = timeit.default_timer() - start_time\n",
        "print(f\"Time elapsed: {elapsed_time} seconds\")\n",
        "\n",
        "\n",
        "merged_model = machine_peft_model.merge_and_unload()\n",
        "\n",
        "# 2. Define a clearer path (don't overwrite the original 'base_model' name!)\n",
        "# Suggested: \"modernbert_finetuned\" or similar\n",
        "save_path = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\machine_model\"\n",
        "\n",
        "# 3. Save the FULL model and tokenizer\n",
        "merged_model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"Full merged model saved to: {save_path}\")\n",
        "\n",
        "del machine_toxicity_model\n",
        "del machine_peft_model\n",
        "del base_trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def evaluate_performance(preds, dataset, dataset_name):\n",
        "    y_true = dataset['label'] \n",
        "    \n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    \n",
        "    print(f\"--- Performance on {dataset_name} ---\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, preds))\n",
        "    print(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "\n",
        "def run_evals(model_path, test_df):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    human_test_df =  test_df[test_df['origin'] == 'human']\n",
        "    machine_test_df =  test_df[test_df['origin'] == 'machine_generated']\n",
        "    \n",
        "    full_tokenized_dataset = prepare_datasets(test_df)\n",
        "    human_tokenized_dataset = prepare_datasets(human_test_df)\n",
        "    machine_tokenized_dataset = prepare_datasets(machine_test_df)\n",
        "\n",
        "    eval_trainer = Trainer(model=model)\n",
        "\n",
        "    full_raw_preds = eval_trainer.predict(full_tokenized_dataset)\n",
        "    full_final_preds = np.argmax(full_raw_preds.predictions, axis=1)\n",
        "    evaluate_performance(full_final_preds, full_tokenized_dataset, \"Full Test Set\")\n",
        "\n",
        "    human_raw_preds = eval_trainer.predict(human_tokenized_dataset)\n",
        "    human_final_preds = np.argmax(human_raw_preds.predictions, axis=1)\n",
        "    evaluate_performance(human_final_preds, human_tokenized_dataset, \"Human Only\")\n",
        "    \n",
        "    machine_raw_preds = eval_trainer.predict(machine_tokenized_dataset)\n",
        "    machine_final_preds = np.argmax(machine_raw_preds.predictions, axis=1)\n",
        "    evaluate_performance(machine_final_preds, machine_tokenized_dataset, \"Machine Only\")\n",
        "\n",
        "    del model\n",
        "    del eval_trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\base_model\"\n",
        "human_path = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\human_model\"\n",
        "machine_path = r\"C:\\Users\\jaydo\\OneDrive\\Documents\\CS\\Fall25CS4824\\pretrained_models_dir\\machine_model\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_evals(base_model, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_evals(human_path, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_evals(machine_path, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7sXn9TUj52Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WsSL84wOAb3"
      },
      "source": [
        "### Unsloth Fine Tuning\n",
        "\n",
        "This is an attempt at getting unsloth to work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2a2lrErOGzY"
      },
      "outputs": [],
      "source": [
        "# !pip install \"unsloth[local]\"\n",
        "# !pip install trl peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44VEoR4jOIjq"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "print(\"Unsloth ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVJEf_EKOKYv"
      },
      "outputs": [],
      "source": [
        "def format_text_for_unsloth(text, label):\n",
        "    \"\"\"Convert your toxicity data to instruction format\"\"\"\n",
        "    instruction = \"Classify this text as toxic or non-toxic.\"\n",
        "    answer = \"toxic\" if label == 1 else \"non-toxic\"\n",
        "\n",
        "    return f\"\"\"### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{text}\n",
        "\n",
        "### Response:\n",
        "{answer}\"\"\"\n",
        "print(\"Formatting your data for Unsloth...\")\n",
        "train_df.loc[:, 'formatted'] = train_df.apply(lambda r: format_text_for_unsloth(r['text'], r['binary_label']), axis=1)\n",
        "val_df.loc[:, 'formatted'] = val_df.apply(lambda r: format_text_for_unsloth(r['text'], r['binary_label']), axis=1)\n",
        "\n",
        "train_sample = train_df.sample(n=2000, random_state=42)  # Start small\n",
        "val_sample = val_df.sample(n=500, random_state=42)\n",
        "\n",
        "print(f\"Ready to train with {len(train_sample)} examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5As_RduONje"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/tinyllama-bnb-4bit\",  # Small model for Colab\n",
        "    max_seq_length=512,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# Add LoRA adapters (makes training faster)\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(\"Model loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJjeXKzOP29"
      },
      "outputs": [],
      "source": [
        "MAX_INPUT_CHARS = 400\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    def format_example(example):\n",
        "\n",
        "        instruction = \"Classify this text as toxic or non-toxic.\"\n",
        "        text = example[\"text\"]\n",
        "        answer = \"toxic\" if example[\"binary_label\"] == 1 else \"non-toxic\"\n",
        "        \n",
        "        example[\"text\"] = f\"\"\"### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{text}\n",
        "\n",
        "### Response:\n",
        "{answer}\"\"\"\n",
        "        return example\n",
        "    \n",
        "    return dataset.map(format_example, num_proc=1)\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_sample[['text', 'binary_label']])\n",
        "val_dataset = Dataset.from_pandas(val_sample[['text', 'binary_label']])\n",
        "\n",
        "train_dataset = preprocess_dataset(train_dataset)\n",
        "val_dataset = preprocess_dataset(val_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    max_seq_length=512,\n",
        "    dataset_text_field=\"text\",\n",
        "    packing=False,\n",
        "    dataset_num_proc=1,  # Disable during tokenization\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"toxicity_unsloth\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=2,  # Reduced\n",
        "        gradient_accumulation_steps=2,   # Reduced\n",
        "        warmup_steps=50,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=False,\n",
        "        bf16=False,\n",
        "        logging_steps=25,\n",
        "        optim=\"adamw_8bit\",\n",
        "        save_strategy=\"epoch\",\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        report_to=\"none\",\n",
        "        dataloader_num_workers=0,  # Disable dataloader workers\n",
        "        dataloader_pin_memory=False,  # Disable pin memory\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess and tokenize manually BEFORE passing to SFTTrainer\n",
        "def create_tokenized_dataset(dataset, tokenizer):\n",
        "    def tokenize_function(example):\n",
        "        MAX_INPUT_CHARS = 400\n",
        "        instruction = \"Classify this text as toxic or non-toxic.\"\n",
        "        text = example[\"text\"][:MAX_INPUT_CHARS]\n",
        "        answer = \"toxic\" if example[\"binary_label\"] == 1 else \"non-toxic\"\n",
        "        \n",
        "        formatted_text = f\"\"\"### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{text}\n",
        "\n",
        "### Response:\n",
        "{answer}\"\"\"\n",
        "        \n",
        "        # Tokenize it here\n",
        "        tokenized = tokenizer(\n",
        "            formatted_text,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=False,\n",
        "        )\n",
        "        return tokenized\n",
        "    \n",
        "    # Tokenize with num_proc=1 to avoid multiprocessing issues\n",
        "    return dataset.map(tokenize_function, remove_columns=dataset.column_names, num_proc=1)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = Dataset.from_pandas(train_sample[['text', 'binary_label']])\n",
        "val_dataset = Dataset.from_pandas(val_sample[['text', 'binary_label']])\n",
        "\n",
        "print(\"Tokenizing datasets manually...\")\n",
        "train_dataset = create_tokenized_dataset(train_dataset, tokenizer)\n",
        "val_dataset = create_tokenized_dataset(val_dataset, tokenizer)\n",
        "print(\"Done!\")\n",
        "\n",
        "# Now use regular Trainer, not SFTTrainer\n",
        "from transformers import Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"toxicity_unsloth\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=2,\n",
        "        warmup_steps=50,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=False,\n",
        "        bf16=False,\n",
        "        logging_steps=25,\n",
        "        optim=\"adamw_8bit\",\n",
        "        save_strategy=\"epoch\",\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        report_to=\"none\",\n",
        "        dataloader_num_workers=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC4HbYFiObvw"
      },
      "outputs": [],
      "source": [
        "# fast func for testing\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def check_toxicity(text):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "Classify this text as toxic or non-toxic.\n",
        "\n",
        "### Input:\n",
        "{text}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens=10, temperature=0.1)\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # extract response\n",
        "    response = result.split(\"### Response:\")[-1].strip().lower()\n",
        "    if \"toxic\" in response and \"non-toxic\" not in response:\n",
        "        return \"toxic\"\n",
        "    return \"non-toxic\"\n",
        "\n",
        "\n",
        "# Test on some examples\n",
        "test_texts = [\n",
        "    \"You did a great job!\",\n",
        "    \"I hate you so much\",\n",
        "    \"This is interesting\",\n",
        "    \"You're an idiot\",\n",
        "    \"I hate that i'm so good at this\",\n",
        "]\n",
        "\n",
        "print(\"\\nTesting the model:\")\n",
        "for text in test_texts:\n",
        "    result = check_toxicity(text)\n",
        "    print(f\"Text: '{text}'  Prediction: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cSmQD7HOgOw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Test on 100 examples\n",
        "test_sample = test_df.sample(n=100, random_state=42)\n",
        "predictions = []\n",
        "true_labels = test_sample['binary_label'].tolist()\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "for text in test_sample['text']:\n",
        "    pred = check_toxicity(text)\n",
        "    predictions.append(1 if pred == \"toxic\" else 0)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"\\nUnsloth Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compare with BERT results\n",
        "print(f\"Your BERT Accuracy: ~0.85 (from your code)\")\n",
        "print(f\"Unsloth Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3IzS0nQawKq"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the path in Google Drive\n",
        "gdrive_path = '/content/drive/MyDrive/Colab Notebooks/my_toxicity_detector'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(gdrive_path, exist_ok=True)\n",
        "\n",
        "# %%% Saves model %%%\n",
        "model.save_pretrained(gdrive_path)\n",
        "tokenizer.save_pretrained(gdrive_path)\n",
        "print(f\"Model saved to '{gdrive_path}'!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9usomztLsl9"
      },
      "source": [
        "### Multi-shot and prompting approaches for toxicity identification\n",
        "\n",
        "This will simply use prompting to identify toxicity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S00I0YAsMhRU"
      },
      "outputs": [],
      "source": [
        "# !pip install cerebras-cloud-sdk\n",
        "# https://inference-docs.cerebras.ai/models/overview\n",
        "# Cerebras key: csk-22y49tpjjx4nfym4pry6eemfrfp9vtyhdwmv5m5jf3826vvm\n",
        "import os\n",
        "from cerebras.cloud.sdk import Cerebras\n",
        "\n",
        "client = Cerebras(\n",
        "    api_key=os.environ.get(\"CEREBRAS_API_KEY\")\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    messages=[{\"role\":\"user\",\"content\":\"Why is fast inference important?\"}],\n",
        "    model=\"llama-3.3-70b\",\n",
        "    max_completion_tokens=1024,\n",
        "    temperature=0.2,\n",
        "    top_p=1,\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "g9usomztLsl9"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
